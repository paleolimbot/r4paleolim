
# Computing statistics in R

Intro

## Prerequisites

The prerequisites for this tutorial are the `tidyverse` and `broom` packages. If these packages aren't installed, you'll have to install them using `install.packages()`.

```{r, eval = FALSE}
install.packages("tidyverse") # will also install the broom package
```

Load the packages when you're done! If there are errors, you may have not installed the above packages correctly!

```{r}
library(tidyverse)
library(rclimateca)
library(broom)
```

Finally, you will need to obtain the sample data...

```{r, results='hide'}
climate_data <- getClimateData(c(27141, 6354), year = 2000:2003,
                               nicenames = TRUE) %>%
  left_join(ecclimatelocs %>% select(station_name = Name, stationid = `Station ID`),
            by = "stationid") %>%
  select(station_name, year, month, everything()) %>%
  select(-ends_with("flag"), -parseddate, -datetime, -stationid)
```

## Terminology

### Grouping Variables

Many statistical test functions in R use a **formula** to specify a value column and a grouping column for a test using a data frame as input. This is usually a column that contains data labels like "group1", "group1", "group1", "group2", "group2", etc., whose values divide observations into groups for which we want to test significance. In our sample data frame `climate_data`, these variables are `station_name`, `year`, `month`. The other variables represent measured values, whereas the grouping variables give context to each row. The **formula** used as input to statistical test functions is generally in the form `measure_var ~ grouping_var`, where `measure_var` and `grouping_var` are columns in a data frame.

Sometimes it is necessary to use column names as grouping variables. In the case of the `climate_data` data frame, one might want to test whether the mean monthly temperature (`meantemp`) is significantly different than the extreme maximum monthly temperature (`extrmaxtemp`). Because these values are stored in two columns, there is no grouping variable that can separate these two sets of observations. This operation is possible using the `gather()` function.

```{r}
climate_data_mean_max_temp <- climate_data %>%
  select(station_name, year, month, meantemp, extrmaxtemp) %>%
  gather(meantemp, extrmaxtemp, key = "temperature_type", value = "temp")
climate_data_mean_max_temp
```

In the resulting data frame, the `temperature_type` column will contain the values "meantemp" and "extrmaxtemp", which can be used as a grouping variable in a statistical test function. When using `gather()`, it is important to select only the relevant variables using `select()` first.

### Paired Values

Some statistical tests are only possible or are preferable with **paired values**, or values that are stored in two columns in a data frame (i.e., part of the same observation). The example above of testing whether the mean monthly temperature (`meantemp`) is significantly different than the extreme maximum monthly temperature (`extrmaxtemp`) could also be done pairwise, in which case the original data is already in the correct format for the test. Sometimes the data is provided in a form where there is a grouping variable, and measured values are in the same column (this is the result of the above example where we converted `meantemp` and `extrmaxtemp` into a grouping variable and a measured variable). We can transform a grouping variable and a measured variable into paired observations using the `spread()` function.

```{r}
climate_data_mean_max_temp %>%
  spread(key = temperature_type, value = temp)
```

In the resulting data frame, the values that were in `temperature_type` are now column names, and the qualifying variables `station_name`, `year`, and `month` are used to identify unique observations that are paired with one another.

### Independent Observations

...don't have a good explanation for this.

### Graphical Test

autocorrelation?


## Testing for Normality

Some tests (notably the t-test, the ANOVA test, and the Pearson coefficient) require that the input values are normally distributed. For small amounts of replicate samples, this is generally a good assumption, however larger samples whose distribution cannot be assumed require a test for normality. One such test is the Shapiro-Wilk test, which is described below.

### Test Data

The test for normality requires a data frame with one column that contains the values that should be normally distributed. In our example, we will test whether or not mean monthly temperature is normally distributed, and whether or not total montly precipitation is normally distributed. It is also good practice to keep qualifying variables that give context to each observation.

```{r}
normal_test_data <- climate_data %>%
  select(station_name, year, month, meantemp, totalprecip)
normal_test_data
```

### Graphical Test

The graphical test for a normality test is a histogram.

```{r}
ggplot(normal_test_data, aes(x = meantemp)) +
  geom_histogram(bins = 30)
```

A historgram of a normally distributed variable should be symmetrical about its mean, like the histogram shown below:

```{r}
set.seed(300)
normal_random_data <- tibble(normal_random_data = rnorm(n = 100, mean = 0, sd = 1))

ggplot(normal_random_data, aes(x = normal_random_data)) +
  geom_histogram(bins = 30)
```

A histogram of a normally distributed variable generally isn't a perfect bell curve (especially when there are few data points), but should show some evidence of symmetry about the mean value.

### Statistical Test

Testing for normality in R involves a call to `shapiro.test()`, followed by a call to `tidy()` in the **broom** package to view the results in the form of a data frame.

```{r}
shapiro.test(normal_test_data$meantemp) %>%
  tidy()
```

A low `p.value` indicates that there is evidence to reject the notion that the input data are sampled from a normally distributed population. You will have to pick a level of significance ($\alpha$) as a threshold, usually 0.05 or 0.01, under which the p-value will indicate the sample was drawn from a non-normal distribution. In our example, the mean montly temperature was shown to be non-normally distributed (*p*<0.001).

In the case of our normal random data, the p-value is quite high (*p*=0.72), suggesting that the data were sampled from a normally distributed population.

```{r}
shapiro.test(normal_random_data$normal_random_data) %>%
  tidy()
```

## Correlation and Linear Regression

Tests for correlation of two variables test whether or not a relationship exists between the two variables (i.e., can any of the variance of one variable be explained by variance in the other). This is often done to test association between two parameters when these measurements are paired. In our example, we will test the corellation between mean monthly temperature and total monthly precipitation, to ascertain whether or not a statistically significant relationship exists between the two.

### Test Data

Correlation tests all require a data frame with one column for the x variable and one column for the y variable. It is often useful to keep other qualifying variables that give context to each observation, but are not required by the test. In our case, the x variable will be `meantemp` and the y variable will be `totalprecip`.

```{r}
correlation_test_data <- climate_data %>% 
  select(station_name, year, month, meantemp, totalprecip)
correlation_test_data
```

### Graphical Test

A graphical test of the correlation of two variables is a biplot with one variable on the x-axis, and one variable on the y-axis. The variable on the x-axis should be the indepenent variable for the purposes of the test. This will look something like `ggplot(my_data_frame, x = independent_var, y = dependent_var)` followed by `geom_point()`. You can add a linear regression to the plot using `stat_smooth(method = lm)`. This will add the best-fit line whose slope and intercept we will calculate in the next section.

```{r}
ggplot(correlation_test_data, aes(x = meantemp, y = totalprecip)) +
  geom_point() +
  stat_smooth(method = lm)
```

Based on inspection of the biplot, you should be able to have a hunch as to whether or not a linear relationship exists between the two variables. In our case, it looks like there is a weak negative correlation between mean temperature and total preciptiation (i.e., the higher the mean temperature for a given month, the lower the total precipitation for the same month).

### The Pearson product-moment correlation coefficient (*r*)

The Pearson product-moment correlation coefficient (usually known as the *r* value) is a test of how well a line of best fit is able to model the data (generally a standard least-squares linear regression). The coefficient ranges from -1 (perfect negative linear relationship) to +1 (perfect positive linear relationship). Generally the square of this value is reported (r^2^), and can be interpreted as "xx % of the variance in `y_variable` can be explained by the variance in `x_variable`". There is no statistical way to test how good the linear relationship is, but it is possible to test that the coefficient is not equal to zero (i.e., it is possible to reject the notion that there `x_variable` and `y_variable` have no linear relationship).

#### Assumptions

The Pearson product-moment correlation coefficient assumes that `x_variable` and `y_variable` are normally distributed.

#### Statistical Test

Calculating the *r* value and associated p-value involves a call to `cor.test()` with `method = "pearson"`, followed by a call to `tidy()` in the **broom** package to get the test results in the form of a data frame.

```{r}
cor.test(~totalprecip + meantemp, data = correlation_test_data, 
         method = "pearson") %>%
  tidy()
```

The `estimate` column contains the *r* value, which you could square to get the *r^2^* value. The `p.value` column contains the p-value, which represents the probability that the two variables have no linear relationship. In our case, `totalprecip` and `meantemp` have a significant negative linear relationship (*p*=0.003).

### Spearman $\rho$ or *r~s~*

The Spearman correlation coefficient (abbreviated $\rho$ or *r~s~*) is a test of a one-to-one relationship between `x_variable` and `y_variable`, not necessarily linear. The test uses ranked values for `x_variable` and `y_variable`, so outliers are less of an issue than they are with the Pearson coefficient. Similar to the Perason coefficient, the *r~s~* value varies from -1 (a perfect one-to-one negative relationship) to 1 (a perfect one-to-one positive relationship). Similar to the Pearson coefficient, it is only possible to test that the value is not equal to zero (i.e., i.e., it is possible to reject the notion that there `x_variable` and `y_variable` have no one-to-one relationship).

#### Assumptions

The Spearman correlation coefficient does not make any assumptions about the distribution of `x_variable` or `y_variable`.

#### Statistical Test

Calculating the *r~s~* value and associated p-value involves a call to `cor.test()` with `method = "spearman"`, followed by a call to `tidy()` in the **broom** package to get the test results in the form of a data frame.

```{r}
cor.test(~totalprecip + meantemp, data = correlation_test_data, 
         method = "spearman") %>%
  tidy()
```

The `estimate` column contains the *r~s~* value, and the `p.value` column contains the p-value, which represents the probability that the two variables are not correlated. In our case, `totalprecip` and `meantemp` have a significant negative relationship (*p*<0.001).

### Linear Regression

Whereas a Pearson coefficient is meant to assess the quality of a linear relationship, linear regression is meant to determine the slope and intercept of that relationship in the form $y = mx + b$, where $y$ is `y_variable`, and x is `x_variable`. By obtaining $m$ and $b$, we can use `x_variable` to calculate `y_variable` for any value of `x_variable`.

#### Assumptions

The standard linear regression (a least-squares regression) works best if both `x_variable` and `y_variable` are symmetrically distributed.

#### Statistical Test

Calculating the coefficients $m$ and $b$ for a linear regression involves a call to `lm()` with a formula `y_variable ~ x_variable` (note this is slightly different than for correlation testing) and `data = my_data_frame`. For our example, the call would look like this:

```{r}
lm(totalprecip ~ meantemp, data = correlation_test_data) %>%
  tidy()
```

The `term` column in the ouput refers to the name of the input column in the righthand side of the input formula, or "(Intercept)" for the intercept, and the `estimate` column refers to the coefficient itself. In the example, this means we can predict  `totalprecip` using the (approximate) expression `-1.44 * meantemp + 101.08`. 

In practice, we want to use the `predict()` function to do this math for us (because if we change some code above that alters which observations are used to create the regression, it will change the coefficient and intercept, and any code that relies on the hard-coded version will be incorrect). This is a three step process: first, save the result of `lm()` to a variable, then create a data frame with a column that has the same name as `x_variable`, then use `mutate()` to create a new column with the predictions from `predict()`. Note that we use a special trick in `mutate()` to pass the entire data frame to the `newdata` argument of `predict()` (the `.` represents the whole data frame as opposed to any particular column, which we can refer to by name within `mutate()`). For our example, we might be interested in the predicted total monthly precipitation values when the mean monthly temperature is 5, 10, 15, and 20 degrees.

```{r}
model <- lm(totalprecip ~ meantemp, data = climate_data)
tibble(meantemp = c(5, 10, 15, 20)) %>%
  mutate(totalprecip_predicted = predict(model, newdata = .))
```

## Significant differences

Tests for significant differences tests whether or not there is a significant difference among various groups of observations. Which test to use depends on whether or not the data are normally distributed, and how many groups exist. For our example, we will be looking at the diferences in mean temperature (`meantemp`) as grouped by several grouping variables (`station_name`, `year`, and `month`).

### Test Data

Tests for significant differences require a data frame with a column containing the values to test, and a column containing the variable to group by (usually contains strings like "group1", "group2", "group3", etc.). It is often useful to keep other qualifying variables that give context to each observation, but are not required by the test. In our case, the column in `climate_data` that contains the values we are testing is `meantemp`, and the columns that contain the groups are `station_name`, `year`, and `month`.

```{r}
difference_test_data <- climate_data %>% 
  select(station_name, year, month, meantemp)
difference_test_data
```

### Graphical Test

The graphic for significant difference tests is a plot with the grouping variable on the x-axis, and the value variable on the y-axis. This is generated using something like `ggplot(my_data_frame, aes(x = group_column, y = value_column))` followed by `geom_point()` and/or `geom_boxplot()`. If the grouping variable is `station_name`, such a plot might look like this:

```{r}
ggplot(difference_test_data, aes(x = station_name, y = meantemp)) +
  geom_boxplot()
```

For smaller numbers of observations, it may make sense to plot the values of the observations themselves using `geom_point()`. In the next example, the grouping variable is `month` (note that we have to use `factor(month)` in `ggplot`, because we are using a continuous variable as a grouping variable).

```{r}
ggplot(difference_test_data, aes(x = factor(month), y = meantemp)) +
  geom_point()
```

When there are a small number of observations in each group, it also may make sense to compute summary statistics and plot those instead of a boxplot or the observations themselves. This is done using `stat_summary()`, which by default displays a point with error bars plus or minus the standard error (the standard deviation divided by the square root of *n*).

```{r}
ggplot(difference_test_data, aes(x = factor(month), y = meantemp)) +
  stat_summary(size = 0.25)
```

Based on the graphic, you should be able to have a hunch as to whether or not one group of observations is significantly different than another group of observations (when grouped by station, it looks like there isn't much difference in temperature, but when grouped by month, there is a clear difference). This is important, because it will make interpreting your results more intuitive and allows you to check for errors.

### The t-test

The t-test tests whether or not there is a significant difference between a value exactly two groups of observations (an ANOVA test can be used when there are more than two groups). We will be using this test to ascertain whether or not there is a significant difference in temperature when these observations are grouped by station (note that there are exactly two stations, Kentville and Greenwood).

#### Assumptions

The t-test assumes that the two samples of data values are normally distributed and independent.

#### Statistical Test

Performing the t-test uses a call to the `t.test()` function in the form `t.test(value_column ~ group_column, data = my_data_frame)`, and a call to the `tidy()` function in the **broom** package to view the results in the form of a data frame. In the case of the Kentville/Greenwood climate data, the two tests look like this:

```{r}
t.test(meantemp ~ station_name, data = difference_test_data) %>% tidy()
```

Here the `estimate` column is the estimated difference between the means of the two groups, and the `p.value` column is the p-value, which represents the probability that there is no significant difference between the two groups (*p*=0.97).

### Paired t-test

Paired version of the t-test...

### Wilcox Rank Sum/Mann-Whitney Test

The Wilcox Rank Sum Test is...

### The ANOVA test

The ANOVA test tests whether or not there is a significant difference between a value using two or more groups of observations (an ANOVA test when there are only two groups is identical to a t-test). We will be using this test to ascertain whether or not there is a significant difference in mean monthly temperature when these observations are grouped by (1) year and (2) month.

#### Assumptions

The ANOVA test assumes all samples of data values are normally distributed and independent.

#### Statistical Test

Performing the ANOVA test uses a call to the `aov()` function in the form `aov(value_column ~ group_column, data = my_data_frame)`, and a call to the `tidy()` function in the **broom** package to view the results in the form of a data frame. In the case of the Kentville/Greenwood climate data, the two tests look like this:

```{r}
aov(meantemp ~ year, data = difference_test_data) %>% tidy()
```

```{r}
aov(meantemp ~ month, data = difference_test_data) %>% tidy()
```

Generally, the only column we care about in the output is the `p.value`, which is the probability that none of the groups of values are significantly different than any others. In the case of the Kentville/Greenwood climate data, there is a significant difference in temperature among months (*p*<0.001), but no significant different in temperature among years (*p*=0.83).

### Krustal-Wallis Rank Sum Test

Krustal Wallis Test...

## Summary

Tutorial summary
